# memory.md 생성 관련 코드 분석 결과

> 분석 대상: openclaw 프로젝트의 memory.md 파일 생성/처리 관련 코드
> 분석 제외: `openclaw-src/` 폴더
> 분석 날짜: 2026-02-24

---

## 핵심 결론

**memory.md 파일은 "생성"되지 않고 "소비(읽기 입력)"됩니다.**

사용자가 직접 작성한 마크다운 파일이 메모리 시스템의 입력 소스가 되며,
실제 메모리 데이터는 SQLite 데이터베이스(`index.sqlite`)에 구조화되어 저장됩니다.

---

## 1. memory.md 파일 인식 로직

**파일**: `openclaw/src/memory/internal.ts` (53-56줄)

```typescript
if (normalized === "MEMORY.md" || normalized === "memory.md") {
  return true;
}
return normalized.startsWith("memory/");
```

시스템이 메모리 파일로 인식하는 경로:
- `/workspace/MEMORY.md` (대문자)
- `/workspace/memory.md` (소문자)
- `/workspace/memory/**/*.md` (하위 디렉토리 전체)

---

## 2. 관련 파일 목록 및 역할

### 핵심 소스 디렉토리: `openclaw/src/memory/`

| 파일 | 역할 |
|------|------|
| `manager.ts` | 메모리 인덱서 중앙 관리 (검색, 동기화, 파일 읽기) |
| `manager-sync-ops.ts` | 파일 감시 및 동기화 로직 (chokidar 기반) |
| `manager-embedding-ops.ts` | 임베딩 생성·청킹·벡터 저장 |
| `internal.ts` | 핵심 유틸리티 (`listMemoryFiles`, `chunkMarkdown`, `buildFileEntry`, `isMemoryPath`) |
| `session-files.ts` | 세션 JSONL 파일 읽기 및 변환 |
| `memory-schema.ts` | SQLite DB 스키마 정의 |
| `embeddings*.ts` | 임베딩 프로바이더 (OpenAI, Gemini, Voyage, Mistral) |

### 확장 디렉토리

| 파일 | 역할 |
|------|------|
| `extensions/memory-core/index.ts` | 플러그인 인터페이스 — `memory_search`, `memory_get` 도구 등록 |
| `extensions/memory-lancedb/index.ts` | LanceDB 기반 대체 벡터 메모리 백엔드 |

---

## 3. 메모리 데이터 처리 흐름

```
메모리 파일들 (MEMORY.md / memory.md / memory/**/*.md)
         │
         ▼
[listMemoryFiles]       ← internal.ts: 파일 목록 수집
         │
         ▼
[buildFileEntry]        ← internal.ts: 경로·크기·해시 추출
         │
         ▼
[chunkMarkdown]         ← internal.ts: 마크다운을 청크 단위로 분할
         │
         ▼
[embedChunksInBatches]  ← manager-embedding-ops.ts: 벡터 임베딩 생성
         │
         ▼
      SQLite DB (index.sqlite)
      ├── chunks         (텍스트 청크)
      ├── chunks_vec     (벡터 저장소)
      ├── chunks_fts     (전문 검색 FTS 인덱스)
      ├── files          (파일 메타데이터)
      └── embedding_cache (임베딩 캐시)
```

---

## 4. 핵심 클래스·함수 분석

### 4-1. `MemoryIndexManager` (`manager.ts`)

메모리 시스템의 중앙 관리자 클래스.

| 메서드 | 설명 |
|--------|------|
| `search()` | 벡터 + 키워드 하이브리드 검색 |
| `readFile()` | 특정 메모리 파일 읽기 |
| `sync()` | 메모리 파일 인덱싱 트리거 |

---

### 4-2. `MemoryManagerSyncOps` (`manager-sync-ops.ts`)

파일 감시(watch) 및 동기화 담당. `chokidar` 라이브러리를 사용하여
파일 추가·변경·삭제를 감지하고 인덱싱을 자동 트리거합니다.

**감시 경로** (359-364줄):
```typescript
const watchPaths = new Set<string>([
  path.join(this.workspaceDir, "MEMORY.md"),
  path.join(this.workspaceDir, "memory.md"),
  path.join(this.workspaceDir, "memory", "**", "*.md"),
]);
```

| 메서드 | 설명 |
|--------|------|
| `ensureWatcher()` | 파일 변경 감시 시작 |
| `syncMemoryFiles()` | 메모리 파일 인덱싱 동기화 |
| `syncSessionFiles()` | 세션 파일 동기화 |

---

### 4-3. `MemoryManagerEmbeddingOps` (`manager-embedding-ops.ts`)

임베딩 생성 및 DB 저장 담당.

**`indexFile()` 메서드 흐름** (693-806줄):
1. 마크다운 파일 읽기
2. `chunkMarkdown()` → 텍스트 청크 생성
3. `embedChunksInBatches()` → 벡터 임베딩 생성
4. DB 저장:
   - `chunks` 테이블: id, path, source, text, embedding
   - `chunks_vec` 테이블: 벡터 데이터
   - `chunks_fts` 테이블: 전문 검색 인덱스
   - `files` 테이블: 파일 메타데이터

---

### 4-4. `chunkMarkdown()` (`internal.ts` 184-265줄)

마크다운 파일을 검색 가능한 청크로 분할하는 함수.

```typescript
chunkMarkdown(content, { tokens, overlap }) {
  // maxChars = tokens * 4 (근사값)
  // 반환: { startLine, endLine, text, hash }[]
}
```

---

## 5. 동기화 트리거 조건

| 트리거 | 메서드 | 설정 조건 |
|--------|--------|-----------|
| 파일 감시 이벤트 | `sync({ reason: "watch" })` | `sync.watch: true` (기본값) |
| 세션 시작 | `sync({ reason: "session-start" })` | `sync.onSessionStart: true` |
| 검색 전 | `sync({ reason: "search" })` | `sync.onSearch: true` |
| 정기 인터벌 | `sync({ reason: "interval" })` | `sync.intervalMinutes > 0` |
| 세션 델타 | `sync({ reason: "session-delta" })` | 임계값 도달 시 |
| 강제 인덱싱 | `sync({ force: true })` | 설정 변경 후 |

---

## 6. 메모리 검색 구조 (하이브리드 검색)

```
검색 쿼리
├── 벡터 검색 (Vector Search)
│   └── chunks_vec 테이블 — 코사인 유사도 기반
├── 키워드 검색 (Full Text Search)
│   └── chunks_fts 테이블 — BM25 기반
└── 결합 (mergeHybridResults)
    └── 벡터 가중치 + 텍스트 가중치 조합
```

---

## 7. 주요 설정 옵션 (`memorySearch`)

```typescript
sync: {
  watch: boolean;              // 파일 변경 감시 활성화
  watchDebounceMs: number;     // 감시 디바운스 시간 (ms)
  onSessionStart: boolean;     // 세션 시작 시 자동 동기화
  onSearch: boolean;           // 검색 전 자동 동기화
  intervalMinutes: number;     // 정기 동기화 주기 (분)
  sessions?: {
    deltaBytes: number;        // 세션 파일 크기 임계값
    deltaMessages: number;     // 세션 메시지 수 임계값
  };
}
```

---

## 8. 플러그인 시스템 연동

### `extensions/memory-core/index.ts`
- `memory_search` 도구 등록: 쿼리 기반 메모리 검색
- `memory_get` 도구 등록: 특정 파일 메모리 조회
- AI 에이전트가 도구 호출을 통해 메모리에 접근할 수 있는 인터페이스 제공

### `extensions/memory-lancedb/index.ts`
- LanceDB 기반 대체 벡터 메모리 백엔드
- 대용량 벡터 데이터 처리에 최적화된 대안 구현

---

## 9. MEMORY.md 생성 및 사용 전체 사이클

```
+-----------------------------------------------------------------------+
|                      MEMORY.md 생성 & 사용 사이클                     |
+-----------------------------------------------------------------------+

  [1. 생성 단계]  사용자 or AI 에이전트가 MEMORY.md 직접 작성
  +-----------------------------------------------------------------+
  |  WHY: AI 는 대화가 끝나면 컨텍스트를 잃는다.                   |
  |       세션을 넘어 지속되어야 할 정보(사용자 선호도, 프로젝트   |
  |       규칙, 반복 지식 등)를 영구 저장소인 마크다운 파일에      |
  |       기록함으로써 "장기 기억" 역할을 부여한다.                |
  |                                                                 |
  |  $ vim /workspace/MEMORY.md                                     |
  |                                                                 |
  |  # 사용자 선호도                                               |
  |  - 언어: 한국어                                                |
  |  - 코드 스타일: TypeScript strict mode                         |
  |  ...                                                           |
  +-----------------------------------------------------------------+
                              |
                              | 파일 저장 (add / change 이벤트)
                              v
  [2. 감지 단계]  chokidar 파일 와처 (manager-sync-ops.ts)
  +-----------------------------------------------------------------+
  |  WHY: 사용자가 언제 파일을 수정할지 알 수 없다.                |
  |       AI 가 주기적으로 직접 파일을 폴링하면 불필요한 I/O 가   |
  |       발생한다. OS 의 파일 이벤트를 구독하는 방식(inotify /   |
  |       FSEvents)으로 변경이 생긴 순간에만 반응해 효율을 높인다.|
  |                                                                 |
  |  ensureWatcher()                                                |
  |    WATCH: /workspace/MEMORY.md          <-- 감지!              |
  |    WATCH: /workspace/memory.md                                 |
  |    WATCH: /workspace/memory/**/*.md                            |
  |                                                                 |
  |    on("add")    --> markDirty() --> sync({ reason:"watch" })   |
  |    on("change") --> markDirty() --> sync({ reason:"watch" })   |
  |    on("unlink") --> markDirty() --> sync({ reason:"watch" })   |
  +-----------------------------------------------------------------+
                              |
                              | sync() 호출
                              v
  [3. 수집 단계]  파일 목록 & 메타데이터 추출 (internal.ts)
  +-----------------------------------------------------------------+
  |  WHY: 워크스페이스에는 메모리 파일이 여러 개 있을 수 있고,    |
  |       전부 다시 인덱싱하면 비용이 크다.                        |
  |       파일 해시(hash)를 DB 에 저장된 이전 값과 비교해          |
  |       실제로 내용이 바뀐 파일만 후속 단계로 넘긴다.           |
  |       (불필요한 임베딩 API 호출 비용 절감)                     |
  |                                                                 |
  |  listMemoryFiles()                                              |
  |    --> isMemoryPath() 로 필터링                                 |
  |        "MEMORY.md" | "memory.md" | "memory/*" 매칭             |
  |                                                                 |
  |  buildFileEntry()                                               |
  |    --> { path, size, hash, mtime }  추출                       |
  |    --> 기존 DB hash 와 비교 --> 변경된 파일만 처리             |
  +-----------------------------------------------------------------+
                              |
                              | 변경 감지된 파일 전달
                              v
  [4. 청킹 단계]  마크다운 분할 (internal.ts: chunkMarkdown)
  +-----------------------------------------------------------------+
  |  WHY: 임베딩 API 는 입력 토큰 한도가 있다(보통 8K 토큰).      |
  |       또한 MEMORY.md 전체를 하나의 벡터로 만들면 검색 시      |
  |       "어느 부분이 관련 있는지" 정밀도가 떨어진다.            |
  |       작은 단위로 나눠야 관련 있는 청크만 정확히 추출된다.    |
  |       overlap 은 청크 경계에서 문맥이 잘리는 것을 방지한다.   |
  |                                                                 |
  |  chunkMarkdown(content, { tokens, overlap })                    |
  |                                                                 |
  |  MEMORY.md 원문                   분할된 청크들                |
  |  +-----------------+              +--------------------+        |
  |  | # 사용자 선호도 |  -------->   | chunk[0]: lines 1-20|       |
  |  | - 언어: 한국어  |              | chunk[1]: lines 18-40|      |
  |  | - 코드 스타일   |              | chunk[2]: lines 38-60|      |
  |  | ...             |              | ...                 |       |
  |  +-----------------+              +--------------------+        |
  |                          (overlap 으로 문맥 연속성 유지)        |
  +-----------------------------------------------------------------+
                              |
                              | 청크 배열 전달
                              v
  [5. 임베딩 단계]  벡터 변환 (manager-embedding-ops.ts)
  +-----------------------------------------------------------------+
  |  WHY: 텍스트 그대로는 "의미적 유사도"를 계산할 수 없다.       |
  |       "한국어로 답해줘" 와 "응답 언어: Korean" 은 표현이 달라도|
  |       같은 의미인데, 키워드 검색만으로는 매칭이 안 된다.       |
  |       텍스트를 고차원 벡터로 변환하면 의미가 가까운 청크가     |
  |       벡터 공간에서도 가까워져 의미 기반 검색이 가능해진다.   |
  |                                                                 |
  |  embedChunksInBatches()                                         |
  |                                                                 |
  |  청크 텍스트          임베딩 API           벡터                |
  |  "언어: 한국어"  -->  [OpenAI /        --> [0.12, -0.34,       |
  |                        Gemini /              0.87, ...]         |
  |                        Voyage /         (1536 or 3072 dim)     |
  |                        Mistral]                                 |
  +-----------------------------------------------------------------+
                              |
                              | 청크 + 벡터 저장
                              v
  [6. 저장 단계]  SQLite DB 기록 (index.sqlite)
  +-----------------------------------------------------------------+
  |  WHY: 임베딩 API 는 유료이고 호출에 시간이 걸린다.             |
  |       매 검색마다 파일을 다시 임베딩하면 비용·속도 모두 문제다.|
  |       한 번 생성한 벡터를 DB 에 캐싱해두면 재사용할 수 있다.  |
  |       또한 SQLite 의 벡터 확장(sqlite-vec)과 FTS5 를 동시에   |
  |       활용해 단일 파일로 두 가지 검색을 모두 지원한다.         |
  |                                                                 |
  |  +------------------+   +------------------+                   |
  |  | files 테이블      |   | chunks 테이블     |                  |
  |  |------------------|   |------------------|                   |
  |  | id               |   | id               |                   |
  |  | path: MEMORY.md  |   | file_id (FK)     |                   |
  |  | hash             |   | source: "memory" |                   |
  |  | size             |   | text (원문 청크) |                   |
  |  | mtime            |   | startLine        |                   |
  |  +------------------+   | endLine          |                   |
  |                         +------------------+                   |
  |  +------------------+   +------------------+                   |
  |  | chunks_vec 테이블 |   | chunks_fts 테이블 |                  |
  |  |------------------|   |------------------|                   |
  |  | id               |   | id               |                   |
  |  | embedding(vector)|   | text (FTS 인덱스)|                   |
  |  | (코사인 유사도용) |   | (BM25 검색용)    |                   |
  |  +------------------+   +------------------+                   |
  +-----------------------------------------------------------------+
                              |
                              | (이후 AI가 응답 생성 시)
                              v
  [7. 검색 단계]  하이브리드 검색 (manager.ts: search)
  +-----------------------------------------------------------------+
  |  WHY: 벡터 검색만 쓰면 정확한 키워드가 무시될 수 있고,        |
  |       키워드 검색만 쓰면 의미적으로 유사한 내용을 놓친다.      |
  |       둘을 병행(하이브리드)하면 의미 유사도 + 정확한 용어     |
  |       매칭을 모두 잡을 수 있어 검색 품질이 높아진다.           |
  |       또한 전체 MEMORY.md 를 컨텍스트에 넣으면 LLM 의 토큰   |
  |       한도를 낭비하므로, 관련 청크만 골라 주입해 효율을 높인다.|
  |                                                                 |
  |  사용자 메시지: "TypeScript 코드 작성해줘"                      |
  |                                                                 |
  |  search(query, { topK, vectorWeight, textWeight })              |
  |                                                                 |
  |  +-----------+     +-------------+     +-------------------+   |
  |  | 쿼리 임베딩 | --> | chunks_vec  | --> | 코사인 유사도 점수 |   |
  |  +-----------+     | (벡터 검색) |     | chunk[1]: 0.92    |   |
  |                    +-------------+     | chunk[4]: 0.87    |   |
  |  +-----------+     +-------------+     +-------------------+   |
  |  | 쿼리 키워드 | --> | chunks_fts  | --> | BM25 점수         |   |
  |  +-----------+     | (FTS 검색)  |     | chunk[1]: 8.3     |   |
  |                    +-------------+     | chunk[2]: 6.1     |   |
  |                                        +-------------------+   |
  |                          |                                     |
  |                          v  mergeHybridResults()               |
  |                   +-------------+                              |
  |                   | 최종 순위    |                              |
  |                   | 1. chunk[1] | <- "코드 스타일: TS strict"  |
  |                   | 2. chunk[4] | <- "언어: 한국어"            |
  |                   +-------------+                              |
  +-----------------------------------------------------------------+
                              |
                              | 검색 결과를 AI 컨텍스트에 주입
                              v
  [8. 활용 단계]  AI 에이전트 응답 생성 (memory-core/index.ts)
  +-----------------------------------------------------------------+
  |  WHY: AI 에이전트는 도구 호출(tool use) 방식으로 외부 데이터를 |
  |       가져온다. 플러그인으로 memory_search / memory_get 을      |
  |       등록해두면 AI 가 필요할 때 스스로 메모리를 조회할 수     |
  |       있다. 이를 통해 MEMORY.md 의 사용자 선호도·규칙이        |
  |       실시간으로 AI 응답에 반영된다.                           |
  |                                                                 |
  |  memory_search 도구 호출                                        |
  |    --> 검색 결과 (관련 MEMORY.md 청크들) 반환                  |
  |                                                                 |
  |  memory_get 도구 호출                                           |
  |    --> 특정 파일 전체 내용 반환                                 |
  |                                                                 |
  |  AI 응답:                                                       |
  |  "TypeScript strict mode 로 코드를 작성하겠습니다..."           |
  |   (MEMORY.md 의 선호도를 반영한 응답)                          |
  +-----------------------------------------------------------------+
                              |
                              | (대화 누적 후 필요 시)
                              v
  [9. 갱신 단계]  MEMORY.md 업데이트 (사이클 반복)
  +-----------------------------------------------------------------+
  |  WHY: 사용자의 선호·프로젝트 맥락은 시간이 지나면서 변한다.   |
  |       대화에서 새로 알게 된 정보를 MEMORY.md 에 추가함으로써  |
  |       AI 가 다음 세션에서도 최신 상태를 기억하도록 한다.       |
  |       이 갱신이 다시 [2. 감지] → [6. 저장] 로 이어져          |
  |       메모리가 지속적으로 진화하는 피드백 루프가 완성된다.     |
  |                                                                 |
  |  AI 에이전트 또는 사용자가 새로운 정보를 MEMORY.md 에 추가     |
  |  --> chokidar 가 변경 감지 --> [2. 감지 단계] 로 복귀          |
  |                                                                 |
  |          +---------------------------------------------+       |
  |          |  MEMORY.md 작성/수정                        |       |
  |          |       |                                     |       |
  |          |       v                                     |       |
  |          |  chokidar 감지 --> sync() --> 재인덱싱      |       |
  |          |       |                                     |       |
  |          |       v                                     |       |
  |          |  SQLite DB 갱신                             |       |
  |          |       |                                     |       |
  |          |       v                                     |       |
  |          |  AI 검색 --> 갱신된 메모리 반영 응답        |       |
  |          |       |                                     |       |
  |          +-------+  (다음 대화에서 반복)               |       |
  +-------------------------------------------------------------+  |
                                                                    |
  동기화 트리거 요약:                                               |
  +-----------------------------+----------------------------------+ |
  | 트리거                      | 조건                            | |
  +-----------------------------+----------------------------------+ |
  | 파일 변경 감지 (watch)      | sync.watch = true (기본값)      | |
  | 세션 시작 (session-start)   | sync.onSessionStart = true      | |
  | 검색 직전 (search)          | sync.onSearch = true            | |
  | 주기적 인터벌 (interval)    | sync.intervalMinutes > 0        | |
  | 세션 델타 (session-delta)   | 메시지/바이트 임계값 도달       | |
  | 강제 재인덱싱 (force)       | 설정 변경 후 수동 트리거        | |
  +-----------------------------+----------------------------------+
```

---

## 요약

| 항목 | 내용 |
|------|------|
| memory.md 역할 | 메모리 시스템의 **입력 소스** (생성 X, 읽기 O) |
| 실제 저장소 | SQLite DB (`index.sqlite`) |
| 파일 감시 | `chokidar` 라이브러리로 실시간 변경 감지 |
| 검색 방식 | 벡터 + FTS 하이브리드 검색 |
| 임베딩 프로바이더 | OpenAI, Gemini, Voyage, Mistral 지원 |
| 진입점 | `manager.ts` → `MemoryIndexManager` 클래스 |
