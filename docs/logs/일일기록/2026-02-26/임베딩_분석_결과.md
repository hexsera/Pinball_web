# OpenClaw 임베딩 분석 결과

> 채팅 과정에서 **언제**, **어떻게** 임베딩이 일어나는지를 코드 수준으로 분석한 문서입니다.
> 코딩 초보자도 이해할 수 있도록 쉽게 설명합니다.

---

## 1. 임베딩이란? (기본 개념)

**임베딩(Embedding)** 이란 텍스트(문장, 단어)를 **숫자 배열(벡터)** 로 변환하는 것입니다.

```
"오늘 날씨가 좋다" → [0.12, -0.34, 0.56, 0.78, ...]  (수백~수천 개의 숫자)
```

왜 이렇게 할까요? 컴퓨터는 글자를 직접 비교하기 어렵지만,
숫자로 바꾸면 **"비슷한 의미의 문장은 비슷한 숫자 배열"** 이 되어
의미적으로 가까운 내용을 쉽게 찾을 수 있습니다.

---

## 2. 전체 흐름도 (아스키아트)

```
┌─────────────────────────────────────────────────────────────────────┐
│                    OpenClaw 임베딩 전체 흐름도                       │
└─────────────────────────────────────────────────────────────────────┘

 [사용자가 채팅 메시지를 보냄]
           │
           ▼
 ┌───────────────────┐
 │  메시지 수신/처리   │  ← 텔레그램, 디스코드, 슬랙 등 채널에서 수신
 └────────┬──────────┘
          │
          ▼
 ┌───────────────────┐     ┌──────────────────────────────────────┐
 │   AI 에이전트가    │────▶│  memory_search(질문) 도구 호출        │
 │   응답을 생성      │     │  "관련된 기억이 있나 검색해볼게"        │
 └────────┬──────────┘     └──────────┬───────────────────────────┘
          │                           │
          │                           ▼
          │                ┌─────────────────────┐
          │                │  질문을 벡터로 변환    │ ← 임베딩 발생! (1)
          │                │  embedQuery(질문)     │
          │                └──────────┬──────────┘
          │                           │
          │                           ▼
          │                ┌─────────────────────┐
          │                │  벡터 유사도 검색      │
          │                │  (코사인 거리 비교)    │
          │                │  + 키워드 검색(FTS)    │
          │                └──────────┬──────────┘
          │                           │
          │                           ▼
          │                ┌─────────────────────┐
          │                │  검색 결과를 에이전트   │
          │                │  에게 전달             │
          │                └─────────────────────┘
          │
          ▼
 ┌───────────────────┐
 │  응답 완료 후       │
 │  세션에 기록 저장    │
 └────────┬──────────┘
          │
          ▼
 ┌───────────────────────────────────────────────┐
 │           동기화(Sync) 시스템                    │
 │                                               │
 │  감시 대상:                                    │
 │  ├─ MEMORY.md 파일 변경                        │
 │  ├─ memory/ 폴더 내 .md 파일 변경               │
 │  └─ 세션 대화 기록(.jsonl) 변경                  │
 │                                               │
 │  변경 감지 시 dirty = true 표시                  │
 │  2~5초 디바운스 후 동기화 시작                    │
 └────────┬──────────────────────────────────────┘
          │
          ▼
 ┌───────────────────────────────────────────────┐
 │          임베딩 생성 파이프라인                    │
 │                                               │
 │  1. 마크다운 파일을 "청크"로 분할                 │
 │     (300토큰씩, 50토큰 겹침)                     │
 │                                               │
 │  2. 각 청크의 SHA256 해시 계산                   │
 │                                               │
 │  3. 캐시 확인                                   │
 │     ├─ 캐시에 있음 → 저장된 벡터 재사용            │
 │     └─ 캐시에 없음 → 새로 임베딩 생성 ← 임베딩! (2)│
 │                                               │
 │  4. 배치로 묶어서 임베딩 API 호출                 │
 │     (한 번에 최대 8000토큰)                      │
 │                                               │
 │  5. 벡터 정규화 (L2 normalization)              │
 │                                               │
 │  6. 데이터베이스에 저장                           │
 │     ├─ embedding_cache 테이블 (캐시)             │
 │     ├─ chunks 테이블 (텍스트 + 벡터)              │
 │     └─ chunks_vec 테이블 (빠른 벡터 검색용)       │
 └───────────────────────────────────────────────┘


 ┌───────────────────────────────────────────────┐
 │       LanceDB 플러그인 (별도 메모리 시스템)       │
 │                                               │
 │  ┌─ 자동 저장 (대화 종료 시)                     │
 │  │  "기억해줘", "내 취향은..." 등 감지             │
 │  │  → 임베딩 생성 → LanceDB에 저장 ← 임베딩! (3) │
 │  │                                             │
 │  ├─ 자동 회상 (대화 시작 시)                     │
 │  │  사용자 질문으로 검색 → 관련 기억 주입           │
 │  │  → 임베딩 생성 ← 임베딩! (4)                  │
 │  │                                             │
 │  └─ 수동 도구                                   │
 │     memory_store(텍스트) → 저장                  │
 │     memory_recall(질문) → 검색                   │
 │     memory_forget(질문) → 삭제                   │
 └───────────────────────────────────────────────┘
```

---

## 3. 임베딩이 발생하는 4가지 시점

### 시점 1: 메모리 검색 시 (질문 임베딩)

**언제?** AI 에이전트가 `memory_search` 도구를 호출할 때

**무슨 일이?**
사용자의 질문을 숫자 배열(벡터)로 변환해서, 저장된 기억들과 비교합니다.

```
사용자: "어제 말한 프로젝트 일정 알려줘"
         ↓
에이전트: memory_search("프로젝트 일정") 호출
         ↓
"프로젝트 일정" → [0.23, -0.45, 0.67, ...]  ← 여기서 임베딩 발생!
         ↓
저장된 기억 벡터들과 코사인 거리 비교
         ↓
가장 비슷한 기억 반환
```

**관련 코드:** `src/memory/manager-embedding-ops.ts` → `embedQueryWithTimeout()`

---

### 시점 2: 파일/세션 동기화 시 (저장 임베딩)

**언제?** 아래 조건에서 자동으로 발생:
- `MEMORY.md` 파일이 수정되었을 때
- `memory/` 폴더의 `.md` 파일이 변경되었을 때
- 채팅 대화 기록이 일정량 이상 쌓였을 때 (5000바이트 또는 5개 메시지)

**무슨 일이?**
변경된 텍스트를 300토큰 크기의 "청크"로 잘라서, 각각을 벡터로 변환합니다.

```
MEMORY.md 파일 변경 감지
         ↓
파일 내용을 300토큰씩 분할 (50토큰 겹침)
         ↓
[청크1] [청크2] [청크3] ...
         ↓
각 청크의 해시값으로 캐시 확인
         ↓
새로운 청크만 임베딩 API 호출  ← 여기서 임베딩 발생!
         ↓
SQLite 데이터베이스에 저장
```

**관련 코드:** `src/memory/manager-sync-ops.ts` → `runSync()`

---

### 시점 3: LanceDB 자동 저장 (대화 종료 시)

**언제?** 대화가 끝날 때 (`agent_end` 훅)

**무슨 일이?**
대화 중 "기억해줘", "내 취향은" 같은 키워드가 포함된 메시지를 자동으로 감지해서 저장합니다.

```
대화 종료
         ↓
사용자 메시지 중 기억할 만한 내용 필터링
         ↓
"나는 매운 음식을 좋아해" → 임베딩 생성  ← 여기서 임베딩 발생!
         ↓
기존 기억과 유사도 0.95 이상이면 중복으로 판단 → 저장 안 함
         ↓
새로운 기억이면 LanceDB에 저장
```

**관련 코드:** `extensions/memory-lancedb/index.ts` → `agent_end` 훅

---

### 시점 4: LanceDB 자동 회상 (대화 시작 시)

**언제?** 새 대화가 시작될 때 (`before_agent_start` 훅)

**무슨 일이?**
사용자의 첫 질문으로 관련 기억을 미리 검색해서 에이전트에게 알려줍니다.

```
사용자: "저녁 메뉴 추천해줘"
         ↓
"저녁 메뉴 추천" → 임베딩 생성  ← 여기서 임베딩 발생!
         ↓
LanceDB에서 유사한 기억 검색
         ↓
"이 사용자는 매운 음식을 좋아합니다" (점수 0.82)
         ↓
에이전트 컨텍스트에 주입
         ↓
에이전트: "매운 음식을 좋아하시니까 마라탕은 어떨까요?"
```

**관련 코드:** `extensions/memory-lancedb/index.ts` → `before_agent_start` 훅

---

## 4. 사용 가능한 임베딩 모델

OpenClaw는 여러 임베딩 모델을 지원하며, 자동 선택(auto)이 기본입니다.

| 제공자 | 모델명 | 벡터 차원수 | 특징 |
|--------|--------|------------|------|
| **로컬** | EmbeddingGemma-300M | 768 | 인터넷 없이 사용 가능, 무료 |
| **OpenAI** | text-embedding-3-small | 1,536 | 가장 일반적, 유료 |
| **OpenAI** | text-embedding-3-large | 3,072 | 고품질, 유료 |
| **Google** | Gemini embedding-001 | 768 | Google API 키 필요 |
| **Voyage** | Voyage AI | 1,024 | Voyage API 키 필요 |
| **Mistral** | Mistral AI | 1,024 | Mistral API 키 필요 |

### 자동 선택(auto) 순서
```
로컬 모델 시도 → OpenAI → Gemini → Voyage → Mistral → FTS 전용 모드
```
API 키가 없으면 다음 모델로 자동 전환됩니다.

---

## 5. 핵심 코드 파일 맵

```
openclaw_git/
├── src/memory/                          ← 핵심 메모리 시스템
│   ├── embeddings.ts                    ← 임베딩 제공자 생성 및 관리
│   ├── embeddings-openai.ts             ← OpenAI 임베딩 구현
│   ├── embeddings-gemini.ts             ← Gemini 임베딩 구현
│   ├── embeddings-mistral.ts            ← Mistral 임베딩 구현
│   ├── embeddings-voyage.ts             ← Voyage 임베딩 구현
│   ├── embeddings-remote-provider.ts    ← 원격 임베딩 배치 처리
│   ├── embedding-chunk-limits.ts        ← 토큰 제한 관리
│   ├── manager.ts                       ← 메모리 매니저 (검색 진입점)
│   ├── manager-embedding-ops.ts         ← 임베딩 생성/캐시/저장
│   ├── manager-sync-ops.ts              ← 파일/세션 동기화
│   ├── manager-search.ts                ← 벡터+FTS 검색
│   ├── internal.ts                      ← 마크다운 청킹
│   ├── session-files.ts                 ← 세션 파일 파싱
│   └── transcript-events.ts             ← 대화 기록 이벤트
│
├── src/agents/tools/
│   └── memory-tool.ts                   ← AI가 호출하는 memory_search 도구
│
├── extensions/memory-core/              ← 메모리 인터페이스 정의
│
└── extensions/memory-lancedb/
    └── index.ts                         ← LanceDB 벡터 메모리 (플러그인)
```

---

## 6. 데이터베이스 구조

임베딩 데이터는 **SQLite 데이터베이스**에 저장됩니다.

```
┌─────────────────────────────────────────┐
│              SQLite DB                   │
│                                         │
│  ┌─────────────────────────┐            │
│  │     files 테이블         │            │
│  │  파일 경로, 해시, 크기    │            │
│  └─────────────────────────┘            │
│                                         │
│  ┌─────────────────────────┐            │
│  │     chunks 테이블        │            │
│  │  청크 텍스트 + 벡터(JSON) │            │
│  │  파일 경로, 줄 번호       │            │
│  └─────────────────────────┘            │
│                                         │
│  ┌─────────────────────────┐            │
│  │   chunks_vec 테이블      │  ← 빠른   │
│  │  벡터만 저장 (sqlite-vec) │    검색용  │
│  └─────────────────────────┘            │
│                                         │
│  ┌─────────────────────────┐            │
│  │   chunks_fts 테이블      │  ← 키워드 │
│  │  전문 검색 인덱스 (FTS)   │    검색용  │
│  └─────────────────────────┘            │
│                                         │
│  ┌─────────────────────────┐            │
│  │  embedding_cache 테이블  │  ← 중복   │
│  │  제공자+모델+해시 → 벡터  │    방지용  │
│  └─────────────────────────┘            │
└─────────────────────────────────────────┘
```

---

## 7. 검색 방식: 하이브리드 검색

OpenClaw는 **벡터 검색 + 키워드 검색**을 합쳐서 사용합니다.

```
사용자 질문: "프로젝트 마감일"
           │
     ┌─────┴─────┐
     ▼           ▼
┌─────────┐  ┌─────────┐
│ 벡터검색  │  │ 키워드   │
│ (의미적)  │  │ 검색     │
│ 가중치    │  │ (FTS)   │
│ 70%     │  │ 가중치   │
│         │  │ 30%     │
└────┬────┘  └────┬────┘
     │            │
     └─────┬──────┘
           ▼
   ┌──────────────┐
   │ 결과 합산     │
   │ + 점수 필터   │
   │ (최소 0.5)   │
   │ + 최대 5개   │
   └──────────────┘
```

- **벡터 검색**: "프로젝트 마감일"과 **의미가 비슷한** 내용을 찾음 (예: "프로젝트 데드라인은 3월 15일")
- **키워드 검색**: "프로젝트", "마감일" 단어가 **정확히 포함된** 내용을 찾음

---

## 8. 성능 최적화 전략

### 캐싱
- 한 번 임베딩된 청크는 **해시값으로 캐시**되어, 내용이 바뀌지 않으면 다시 임베딩하지 않음
- 캐시 최대 10,000개 항목 (오래된 것부터 삭제)

### 배치 처리
- 여러 청크를 **한꺼번에 묶어서** API 호출 (한 번에 최대 8,000토큰)
- 최대 2개의 배치를 동시에 처리

### 오류 대응
- API 실패 시 **최대 3번 재시도** (500ms → 1s → 2s → ... 최대 8s 간격)
- 원격 제공자 실패 시 → 로컬 모델로 자동 전환
- 로컬도 실패 시 → 키워드 검색(FTS)만 사용

### 디바운스
- 파일 변경이 연속으로 발생해도 **2~5초 기다린 후** 한 번만 동기화
- 세션 기록도 **5초 디바운스**로 불필요한 재처리 방지

---

## 9. 주요 설정값

| 설정 | 기본값 | 설명 |
|------|--------|------|
| 청크 크기 | 300 토큰 | 텍스트를 나누는 단위 |
| 청크 겹침 | 50 토큰 | 문맥 유지를 위한 겹침 |
| 벡터 가중치 | 0.7 (70%) | 하이브리드 검색에서 벡터 비중 |
| 키워드 가중치 | 0.3 (30%) | 하이브리드 검색에서 키워드 비중 |
| 최소 점수 | 0.5 | 이 점수 이하 결과는 버림 |
| 최대 결과 수 | 5개 | 검색 결과 최대 개수 |
| 캐시 최대 항목 | 10,000개 | 임베딩 캐시 크기 제한 |
| 세션 변경 기준 | 5,000바이트 또는 5메시지 | 이만큼 쌓이면 동기화 |
| 원격 타임아웃 | 60초 (질의), 120초 (배치) | API 응답 대기 시간 |
| 로컬 타임아웃 | 5분 (질의), 10분 (배치) | 로컬 모델 처리 시간 |

---

## 10. SQLite DB vs LanceDB 심층 비교

### 10-1. 왜 두 가지 데이터베이스를 쓸까?

한마디로, **용도가 다릅니다.**

비유하자면:
- **SQLite DB** = **도서관 서가 시스템** (파일과 문서를 체계적으로 정리해서 검색)
- **LanceDB** = **개인 다이어리** (대화 중 중요한 내용만 골라서 기억)

```
┌───────────────────────────────────────────────────────────────┐
│                    두 DB의 역할 비교                            │
├──────────────────────────┬────────────────────────────────────┤
│      SQLite DB (내장)     │       LanceDB (플러그인)            │
├──────────────────────────┼────────────────────────────────────┤
│                          │                                    │
│  "문서/파일을 쪼개서       │  "대화 중 중요한 말을               │
│   검색할 수 있게 정리"     │   자동으로 기억"                    │
│                          │                                    │
│  MEMORY.md 파일 →         │  "매운 음식 좋아해" →               │
│  300토큰씩 잘라서 →       │  그대로 벡터로 변환 →               │
│  각각 벡터로 변환 →       │  LanceDB에 저장                    │
│  SQLite에 저장            │                                    │
│                          │                                    │
│  ✅ 항상 사용 가능 (기본)   │  ⚡ 선택적 플러그인                 │
│  ✅ 벡터 + 키워드 검색     │  ⚡ 벡터 검색만                    │
│  ✅ 로컬 임베딩 가능       │  ⚡ OpenAI API 키 필요              │
└──────────────────────────┴────────────────────────────────────┘
```

**둘은 함께 사용되지 않습니다.** 사용자가 하나를 선택합니다:
- 기본값은 SQLite DB (내장)
- LanceDB는 별도 플러그인으로 등록해야 사용 가능

---

### 10-2. SQLite DB — 상세 설명

#### 왜 사용하나?

OpenClaw의 **기본 메모리 백엔드**입니다.
`MEMORY.md` 파일, `memory/` 폴더의 문서, 채팅 세션 기록 등을
**잘게 쪼개서(청크)** 벡터로 변환하고, 나중에 검색할 수 있게 저장합니다.

#### 어떤 데이터를 저장하나?

```
┌─────────────────────────────────────────────────────────────┐
│                   SQLite DB 테이블 구조                       │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  meta 테이블 — "설정 정보 메모장"                      │   │
│  │                                                      │   │
│  │  저장 내용:                                           │   │
│  │  ├─ 현재 사용 중인 임베딩 모델 이름                     │   │
│  │  ├─ 임베딩 제공자 (openai, local 등)                   │   │
│  │  └─ 벡터 차원 수 (1536, 768 등)                       │   │
│  │                                                      │   │
│  │  예시: { key: "model", value: "text-embedding-3-small" }│  │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  files 테이블 — "어떤 파일을 처리했는지 기록"            │   │
│  │                                                      │   │
│  │  저장 내용:                                           │   │
│  │  ├─ 파일 경로 (예: memory/프로젝트.md)                  │   │
│  │  ├─ 파일 해시 (내용이 바뀌었는지 확인용)                 │   │
│  │  ├─ 파일 크기                                         │   │
│  │  └─ 마지막 수정 시간                                   │   │
│  │                                                      │   │
│  │  용도: 파일이 변경되지 않았으면 다시 처리하지 않음         │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  chunks 테이블 — "잘게 쪼갠 텍스트 + 벡터" (핵심!)      │   │
│  │                                                      │   │
│  │  저장 내용:                                           │   │
│  │  ├─ 청크 ID (고유 식별자)                              │   │
│  │  ├─ 원본 파일 경로                                    │   │
│  │  ├─ 시작/끝 줄 번호 (원본에서 몇째 줄인지)              │   │
│  │  ├─ 텍스트 원문                                       │   │
│  │  ├─ 임베딩 벡터 (JSON 문자열 형태)                     │   │
│  │  ├─ 내용 해시 (SHA256)                                │   │
│  │  └─ 사용된 모델명                                     │   │
│  │                                                      │   │
│  │  예시: {                                              │   │
│  │    path: "MEMORY.md",                                 │   │
│  │    start_line: 1, end_line: 15,                       │   │
│  │    text: "프로젝트 마감일은 3월 15일...",                │   │
│  │    embedding: "[0.12, -0.34, 0.56, ...]"              │   │
│  │  }                                                    │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  chunks_vec 테이블 — "빠른 벡터 검색 전용"              │   │
│  │  (sqlite-vec 확장 필요)                                │   │
│  │                                                      │   │
│  │  chunks 테이블의 벡터만 따로 저장해서                    │   │
│  │  코사인 거리 계산을 빠르게 수행                          │   │
│  │                                                      │   │
│  │  없으면? → 메모리에 벡터를 전부 올려서 비교 (느림)       │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  chunks_fts 테이블 — "키워드 검색 전용"                 │   │
│  │  (SQLite FTS5 모듈)                                   │   │
│  │                                                      │   │
│  │  "프로젝트"라는 단어가 포함된 청크를 빠르게 찾기 위한     │   │
│  │  전문 검색 인덱스                                      │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  embedding_cache 테이블 — "임베딩 결과 캐시"            │   │
│  │                                                      │   │
│  │  같은 텍스트를 또 임베딩하지 않기 위한 캐시               │   │
│  │  제공자+모델+해시 조합으로 중복 판별                     │   │
│  │  최대 10,000개까지 보관 (오래된 것부터 삭제)             │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

#### 언제 호출되나?

```
┌─────────────────────────────────────────────────────────┐
│              SQLite DB 호출 타이밍                        │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  [DB 생성/열기]                                          │
│  ├─ 메모리 매니저가 처음 만들어질 때 (즉시, 지연 없음)      │
│  ├─ 파일 경로: ~/.openclaw/memory/sqlite.db              │
│  └─ 테이블이 없으면 자동 생성 (ensureSchema)               │
│                                                         │
│  [쓰기 (Write)]                                          │
│  ├─ MEMORY.md 파일이 수정되었을 때                        │
│  │   → 파일 내용을 청크로 분할                            │
│  │   → files, chunks, chunks_vec, chunks_fts에 저장      │
│  │                                                      │
│  ├─ 대화 기록이 5,000바이트 또는 5개 메시지 쌓였을 때       │
│  │   → 세션 내용을 청크로 분할                            │
│  │   → chunks, chunks_vec, chunks_fts에 저장             │
│  │                                                      │
│  └─ 임베딩이 새로 계산되었을 때                            │
│      → embedding_cache에 저장                            │
│                                                         │
│  [읽기 (Read)]                                           │
│  ├─ AI가 memory_search 도구를 호출할 때                   │
│  │   → chunks_vec에서 벡터 검색                          │
│  │   → chunks_fts에서 키워드 검색                        │
│  │   → 결과 합산 후 반환                                 │
│  │                                                      │
│  ├─ 동기화 시작 전 파일 변경 확인                          │
│  │   → files 테이블에서 해시 비교                         │
│  │                                                      │
│  └─ 임베딩 전 캐시 확인                                   │
│      → embedding_cache에서 조회                          │
└─────────────────────────────────────────────────────────┘
```

#### 디스크에 저장되는 파일

```
~/.openclaw/memory/
├── sqlite.db        ← 메인 데이터베이스 파일
├── sqlite.db-wal    ← WAL (Write-Ahead Log, 쓰기 성능 최적화)
└── sqlite.db-shm    ← 공유 메모리 (동시 접근 관리)
```

---

### 10-3. LanceDB — 상세 설명

#### 왜 사용하나?

**대화 기억 전문 플러그인**입니다.
채팅 중에 사용자가 말한 취향, 사실, 결정 등을
**자동으로 감지해서 기억**하고, 다음 대화에서 **자동으로 떠올려줍니다.**

SQLite 내장 시스템보다 **더 간단하고 대화 중심**입니다.

#### 어떤 데이터를 저장하나?

```
┌─────────────────────────────────────────────────────────────┐
│                  LanceDB 테이블 구조                          │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  memories 테이블 — 딱 하나! (단순함이 장점)             │   │
│  │                                                      │   │
│  │  저장 내용:                                           │   │
│  │  ├─ id: 고유 식별자 (UUID)                            │   │
│  │  ├─ text: 기억할 내용 원문                             │   │
│  │  │   예: "나는 매운 음식을 좋아해"                      │   │
│  │  ├─ vector: 임베딩 벡터 (숫자 배열)                    │   │
│  │  │   예: [0.12, -0.34, 0.56, ...]                    │   │
│  │  ├─ importance: 중요도 (0~1)                          │   │
│  │  │   예: 0.8                                         │   │
│  │  ├─ category: 분류                                    │   │
│  │  │   "preference" (취향)                              │   │
│  │  │   "fact" (사실)                                    │   │
│  │  │   "decision" (결정)                                │   │
│  │  │   "entity" (인물/장소)                              │   │
│  │  │   "other" (기타)                                   │   │
│  │  └─ createdAt: 저장된 시각                             │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                             │
│  비교: SQLite는 5개 테이블, LanceDB는 1개 테이블!            │
└─────────────────────────────────────────────────────────────┘
```

#### 언제 호출되나?

```
┌─────────────────────────────────────────────────────────┐
│              LanceDB 호출 타이밍                          │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  [DB 생성/열기]                                          │
│  ├─ 처음 사용할 때 (지연 초기화, lazy)                     │
│  │   → store, search, delete 중 하나가 처음 호출될 때     │
│  ├─ 파일 경로: ~/.openclaw/memory/lancedb/               │
│  └─ memories 테이블이 없으면 자동 생성                     │
│                                                         │
│  [자동 쓰기 — 대화 종료 시] (agent_end 훅)                │
│  ├─ 대화가 끝나면 사용자 메시지를 검사                     │
│  ├─ "기억해줘", "내 취향은", "항상 ~해줘" 등 감지          │
│  ├─ 감지된 내용을 벡터로 변환 (OpenAI API)                │
│  ├─ 기존 기억과 유사도 비교 (0.95 이상이면 중복 → 저장 X)  │
│  └─ 새로운 기억이면 memories 테이블에 저장                 │
│     → 대화당 최대 3개까지만 저장                          │
│                                                         │
│  [자동 읽기 — 대화 시작 시] (before_agent_start 훅)       │
│  ├─ 사용자의 첫 질문을 벡터로 변환                        │
│  ├─ memories 테이블에서 유사한 기억 검색                   │
│  ├─ 점수 0.3 이상인 상위 3개 선택                        │
│  └─ AI 에이전트 컨텍스트에 주입                           │
│     → "이 사용자는 매운 음식을 좋아합니다" 같은 정보 제공  │
│                                                         │
│  [수동 호출 — AI 도구]                                    │
│  ├─ memory_store("텍스트") → 직접 기억 저장               │
│  ├─ memory_recall("질문") → 직접 기억 검색               │
│  └─ memory_forget("질문") → 기억 삭제 (GDPR 대응)        │
└─────────────────────────────────────────────────────────┘
```

#### 디스크에 저장되는 파일

```
~/.openclaw/memory/lancedb/
└── lance/
    └── [Lance 포맷 데이터 파일들]  ← 벡터 데이터 전용 포맷
```

---

### 10-4. 한눈에 비교표

| 비교 항목 | SQLite DB (내장) | LanceDB (플러그인) |
|-----------|-----------------|-------------------|
| **역할** | 문서/파일 인덱싱 | 대화 기억 관리 |
| **기본 제공?** | O (기본값) | X (별도 설치 필요) |
| **초기화 시점** | 매니저 생성 즉시 | 첫 사용 시 (지연) |
| **테이블 수** | 5개 | 1개 |
| **저장 대상** | 파일 청크 (300토큰 단위) | 대화 중 중요 발언 |
| **검색 방식** | 벡터 + 키워드 (하이브리드) | 벡터 검색만 |
| **임베딩 모델** | auto (로컬/OpenAI/Gemini 등) | OpenAI만 |
| **자동 저장** | 파일 변경 감지 시 | 대화 종료 시 (훅) |
| **자동 검색** | memory_search 도구 호출 시 | 대화 시작 시 (훅) |
| **캐싱** | 있음 (embedding_cache) | 없음 |
| **FTS 지원** | O (키워드 검색) | X |
| **중복 방지** | 해시값 비교 | 유사도 0.95 비교 |
| **DB 파일 위치** | `~/.openclaw/memory/sqlite.db` | `~/.openclaw/memory/lancedb/` |
| **필요 API 키** | 없음 (로컬 가능) | OpenAI 키 필수 |

---

### 10-5. 실제 사용 시나리오로 이해하기

#### 시나리오 A: SQLite DB 사용 (기본)

```
[1일차]
사용자가 MEMORY.md에 "프로젝트 마감일: 3월 15일" 작성
         ↓
파일 변경 감지 (Chokidar 워처)
         ↓
"프로젝트 마감일: 3월 15일"을 벡터로 변환
         ↓
SQLite의 chunks 테이블에 저장

[3일차]
사용자: "마감일이 언제였지?"
         ↓
AI가 memory_search("마감일") 호출
         ↓
"마감일" → 벡터로 변환
         ↓
SQLite의 chunks_vec에서 유사 벡터 검색
+ chunks_fts에서 "마감일" 키워드 검색
         ↓
"프로젝트 마감일: 3월 15일" 발견! (점수 0.87)
         ↓
AI: "프로젝트 마감일은 3월 15일입니다."
```

#### 시나리오 B: LanceDB 사용 (플러그인)

```
[1일차 대화]
사용자: "나는 Python보다 TypeScript를 선호해. 기억해줘."
AI: "네, 기억하겠습니다!"
         ↓
대화 종료 (agent_end 훅 발동)
         ↓
"기억해줘" 키워드 감지!
         ↓
"TypeScript를 선호" → 벡터로 변환 (OpenAI API)
         ↓
LanceDB의 memories 테이블에 저장
  category: "preference", importance: 0.8

[3일차 대화]
사용자: "새 프로젝트 시작하려는데 도와줘"
         ↓
대화 시작 (before_agent_start 훅 발동)
         ↓
"새 프로젝트 시작" → 벡터로 변환
         ↓
LanceDB에서 유사 기억 검색
         ↓
"이 사용자는 TypeScript를 선호합니다" 발견! (점수 0.72)
         ↓
AI 컨텍스트에 주입
         ↓
AI: "TypeScript 기반으로 프로젝트를 세팅해볼까요?"
```

---

## 11. 요약

| 질문 | 답변 |
|------|------|
| **임베딩이 뭐야?** | 텍스트를 숫자 배열로 바꾸는 것. 비슷한 의미 = 비슷한 숫자 |
| **언제 발생해?** | (1) 메모리 검색 시 (2) 파일 변경 시 (3) 대화 종료 시 (4) 대화 시작 시 |
| **왜 하는 거야?** | 과거 대화/메모를 의미 기반으로 검색하기 위해 |
| **어디에 저장돼?** | SQLite DB (chunks, chunks_vec 테이블) 또는 LanceDB |
| **어떤 모델 써?** | 기본은 auto (로컬→OpenAI→Gemini→Voyage→Mistral 순서) |
| **비용이 드나?** | 로컬 모델은 무료, 원격 모델은 API 사용료 발생 |
| **캐싱 되나?** | 같은 내용은 해시로 캐시되어 중복 임베딩 방지 |
