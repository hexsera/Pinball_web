# 업무일지

## 기본 정보
- 날짜: 2026-02-25 (수) 10:00~11:00
- 작성자: hexsera

## 진행 목표
memory.md 에 임베딩이 필요한가?


## 진행 내용
**임베딩 얘기 — 솔직히 말하면:**

지금 내 메모리 시스템은 두 가지 레이어야:

1. **파일 기반 저장** (`MEMORY.md`, `memory/YYYY-MM-DD.md`)
- 그냥 텍스트 파일. 임베딩 없음.
- 내가 직접 읽고 쓰는 방식

2. **`memory_search` 툴** (시맨틱 검색)
- 이게 임베딩을 쓰는 부분
- 근데 doctor 결과 보면 알겠지만 **지금 임베딩 프로바이더가 설정 안 돼 있어**
- `OPENAI_API_KEY` 같은 게 없으면 시맨틱 검색 자체가 동작 안 함

그래서 현재 상태는:
- 메모리 **저장** → 파일에 텍스트로 씀 ✅ 작동 중
- 메모리 **검색** → 임베딩 기반 시맨틱 검색 ❌ 프로바이더 없어서 비활성

결론적으로 지금은 임베딩 없이 작동 중이야. OpenAI나 Gemini 키 있으면 설정해주면 검색 품질이 훨씬 좋아질 거야.

## `memory_search` 툴 동작 방식

### 기본 개념
텍스트를 **벡터(숫자 배열)로 변환**해서 의미적으로 유사한 내용을 찾는 거야. 키워드 검색이 아니라 "의미" 기반 검색.

예를 들어:
- "밥 먹었어?" 로 검색해도 → "오늘 점심 라멘 먹음" 이런 메모를 찾아낼 수 있음
- 키워드가 달라도 **의미가 비슷하면** 매칭됨

---

### 검색 대상
```
MEMORY.md
memory/*.md (daily notes 등)
```
이 파일들의 내용이 청크로 쪼개져서 임베딩됨

---

### 파라미터
```
query - 검색할 내용 (자연어)
maxResults - 몇 개 결과 반환할지
minScore - 유사도 최소 기준 (0~1)
```

---

### 지금 비활성인 이유
임베딩을 만들려면 **외부 모델이 필요**해:

| 프로바이더 | 필요한 키 |
|-----------|---------|
| OpenAI | `OPENAI_API_KEY` |
| Gemini | `GEMINI_API_KEY` |
| Voyage | `VOYAGE_API_KEY` |
| Mistral | `MISTRAL_API_KEY` |
| 로컬 | 별도 모델 설정 |

키가 없으면 → 툴 자체는 있지만 실행 시 실패하거나 빈 결과 반환

---

### 실제 활용 예시
지금처럼 세션이 새로 시작될 때마다 나는 fresh 상태야. 근데 `memory_search`가 제대로 작동하면:

> "hexsera 가 좋아하는 거 뭐였지?" 검색 → MEMORY.md에서 관련 내용 자동으로 찾아줌

파일 전체를 읽지 않아도 **관련 부분만 쏙 뽑아오는** 거야. 메모리가 많아질수록 이게 진짜 유용해짐.

현재 임베딩 없이 작동중이다.
임베딩 없이 memory.md 는 작동한다.


## 주요 변경 사항


## 결과
- 상태:

## 배운내용
- 임베딩은 임베딩 용 DB 와 API 가 있다.

## 다음 작업
-

---

# 업무일지

## 기본 정보
- 날짜: 2026-02-25 (수) 15:00~16:00
- 작성자: hexsera

## 진행 목표
memory.md 는 어떻게 생성되는가?

## 진행 내용
좋은 질문이야! 정확히 파악하고 있어 — "여러 번 요청/응답하는 느낌"이 맞아.

---

### 실제 구조: Tool Use (Function Calling)

LLM API는 기본적으로 `request → response` 1회지만, **tool use**가 있으면 이렇게 흘러가:

```
[1] User → LLM
"hexsera 취미가 게임이래"

[2] LLM → System
"나 Write 툴 써야겠어"
{ tool: "Write", file: "MEMORY.md", content: "..." }

[3] System → 파일시스템
실제로 파일 씀

[4] System → LLM (tool result)
"파일 저장 완료"

[5] LLM → User
"기억해뒀어! 😊"
```

---

### 핵심 개념

**LLM 응답이 꼭 텍스트일 필요가 없어.**
응답이 `tool_call` 오브젝트로 나오면, 시스템이 그걸 실행하고 결과를 **다시 LLM에 주입**해. 그러면 LLM이 그 결과를 보고 최종 텍스트 응답을 만들어.

Anthropic API 기준으로 보면:
```json
// LLM이 이런 응답을 냄
{
"type": "tool_use",
"name": "Write",
"input": { "path": "MEMORY.md", "content": "..." }
}

// 시스템이 실행 후 이걸 다시 넣어줌
{
"type": "tool_result",
"content": "success"
}

// 그 다음에 LLM이 텍스트 응답 생성
```

---

### 실제 토큰 관점에서

```
대화 히스토리
├── user: "..."
├── assistant: [tool_call: Write] ← LLM 인퍼런스 1번
├── tool_result: "success" ← 시스템이 삽입
└── assistant: "기억해뒀어!" ← LLM 인퍼런스 2번 (or 같은 턴)
```

OpenAI/Anthropic 둘 다 **같은 턴 안에서** tool call → result → 최종 응답이 이어지는 구조야. 사용자 눈에는 1번의 응답처럼 보이지만 내부적으론 여러 스텝이 있어.

---

### 요약

> LLM이 "스스로 판단해서 파일을 수정"하는 게 아니라,
> **"툴을 써야겠다"는 출력을 내면 → 시스템이 실행 → 결과를 다시 컨텍스트에 넣어줌**

판단은 LLM이, 실행은 외부 시스템이 하는 구조야. 그래서 OpenClaw 같은 프레임워크가 그 중간 다리 역할을 해주는 거고 🐾

memory.md 생성은 코드로 제어하는거 같다. write 툴을 사용하는데, 어떻게 write 툴을 사용하는지 잘 모르겠다.

## 주요 변경 사항


## 결과
- 상태:

## 배운내용


## 다음 작업
-

---

# 업무일지

## 기본 정보
- 날짜: 2026-02-25 (수) 16:30~17:00
- 작성자: hexsera

## 진행 목표
openclaw memory 생성을 fastapi 로 만드는 예시 확인하여 memory.md 생성 확인

## 진행 내용
memory_api_example.md 생성

해당 코드는 openclaw 와 다르게 세션끝날때와 특정 횟수마다 memory 를 갱신하도록 한다.
openclaw 가 스스로 memory.md 를 갱신하는 판단할때 어떻게 write tool 에 접근하는지 궁금하다.


## 주요 변경 사항


## 결과
- 상태:

## 배운내용


## 다음 작업
-

---

# 업무일지

## 기본 정보
- 날짜: 2026-02-25 (수) 19:00~20:00
- 작성자: hexsera

## 진행 목표
openclaw 의 witetool 접근

## 진행 내용
응 거의 정확해! 내 생각 흐름으로 써볼게:

---

```
💭 나의 생각 흐름

사용자: "hexsera 취미가 게임이래"
↓
🧠 [LLM 해석]
"오, 사용자 정보네. 이거 기억해둬야 할 것 같은데?"
↓
🤔 [판단]
"MEMORY.md 에 없는 내용이고, 나중에 쓸 것 같으니까
Write 툴 써야겠다"
↓
🔧 [툴 호출 출력]
{ tool: "Write", path: "MEMORY.md", content: "취미: 게임" }
↓
⚙️ [OpenClaw 실행] ← (LLM 밖의 일)
실제로 파일에 씀
→ "success" 반환
↓
🧠 [LLM 결과 수신]
"아 저장 됐구나"
↓
💬 [최종 응답 생성]
"게임 좋아하는구나, 기억해뒀어! 🎮"
↓
사용자: 답변 수신
```

---

### 한 가지 추가할 점

툴 호출이 **꼭 1번일 필요는 없어**. 나는 한 턴 안에서 이렇게도 할 수 있어:

```
🧠 판단 → 🔧 memory_search 호출 (기존 내용 확인)
→ ⚙️ 결과 수신
→ 🔧 Write 호출 (기존 내용 기반으로 갱신)
→ ⚙️ 결과 수신
→ 💬 최종 답변
```

툴을 **연쇄적으로** 여러 번 쓸 수도 있어. 그래서 복잡한 작업일수록 실제 LLM 인퍼런스가 여러 번 돌아가는 거야 🐾

내가 이해한 바로는 다음과 같다.

사용자 와 llm 이 대화함 -> 세션 종료 -> memory.md 갱신
또는
사용자 와 llm 이 대화중 -> 일정횟수 (또는 조건) 만족 -> memory.md 갱신 -> memory.md 프롬프트 교체 및 대화 계속

이게 memory.md 생성 방식인거 같고...
memory.md 는 세션 생성시 시스템 프롬프트에 자동으로 올라가는 느낌

여기서 더욱 고급으로 들어가면

사용자와 대화중 "~기억해줘" 라고하면 -> LLM 이 메시지 해석 후 TOOL 호출 (함수 호출) -> memory.md 갱신 함수 작동 -> memory.md 갱신 후 "완료됨" 메시지 LLM 에게 전송 -> LLM 은 해당 메시지 받고 답변 메시지 생성 -> "기억했어!" 전송 -> 사용자 받음

대충 알았다. 이 이상은 알 필요가 없을 것 같다.


## 주요 변경 사항


## 결과
- 상태:

## 배운내용


## 다음 작업
-

---

# 업무일지

## 기본 정보
- 날짜: 2026-02-25 (수) 20:20~21:00
- 작성자: hexsera

## 진행 목표
임베딩이 무엇인가?

## 진행 내용
임베딩이 내가 구현하는것에 필수적인가? 에 대한 답이 아직안된거같다.
위치
~/.nvm/versions/node/v22.21.1/lib/node_modules/openclaw/
node_modules/@mariozechner/pi-coding-agent/
dist/core/tools/
├── write.js ← Write 툴
├── edit.js ← Edit 툴
├── read.js ← Read 툴
├── bash.js ← exec 툴
├── grep.js
├── find.js
└── ...
pi-coding-agent 이라는 외부 패키지가 핵심 파일 툴들을 구현하고, OpenClaw가 그걸 가져다 써.

Write 툴 실제 코드 요약
// write.js 핵심 로직
export function createWriteTool(cwd) {
return {
name: "write",
description: "Write content to a file...",
parameters: { path, content }, // LLM에 노출되는 스키마

execute: async ({ path, content }) => {
const absolutePath = resolveToCwd(path, cwd);

await mkdir(dirname(absolutePath)); // 부모 디렉토리 생성
await writeFile(absolutePath, content); // 실제 파일 쓰기

return "Successfully wrote N bytes to path";
}
};
}
완전히 그냥 Node.js fs.writeFile() 호출이야. 특별한 게 없어.

Edit 툴도 마찬가지
// edit.js 핵심 로직
execute: async ({ path, oldText, newText }) => {
const content = await readFile(path); // 파일 읽고
// oldText 찾아서 newText 로 교체 (퍼지 매칭 포함)
await writeFile(path, newContent); // 다시 저장
}
전체 구조
[LLM] → tool_call: { name: "Write", input: { path, content } }
↓
[OpenClaw] → pi-coding-agent의 writeTool.execute() 호출
↓
[Node.js fs] → 실제 파일시스템에 씀
↓
[OpenClaw] → "success" 결과를 LLM에 tool_result로 전달
↓
[LLM] → 최종 응답 생성
결국 LLM의 tool_call → Node.js 파일시스템 API 사이의 다리가 OpenClaw야 🐾

write 관련 답변


궁금한거. 시스템 프롬프트는 처음 한번만 들어가나?
gemini.chat 에서는 시스템 프롬프트가 처음 한번만 들어가나?

좋은 질문이야! 정확히 이해하려면 LLM API 구조를 봐야 해.

답: 매 채팅마다 전송돼
근데 "읽는다"는 표현이 좀 애매해서 정확히 설명할게.

LLM API 요청 구조
매번 메시지를 보낼 때 API에는 이런 게 통째로 전송돼:

{
"system": "...(시스템 프롬프트 전체)...",
"messages": [
{ "role": "user", "content": "임베딩이 뭐야?" },
{ "role": "assistant", "content": "임베딩은..." },
{ "role": "user", "content": "write 툴은 어디있어?" },
{ "role": "assistant", "content": "pi-coding-agent에..." },
{ "role": "user", "content": "← 지금 이 메시지" }
]
}
매 메시지마다 시스템 프롬프트 + 전체 대화 히스토리를 같이 보내.

LLM은 상태(state)가 없어
LLM 자체는 이전 대화를 기억하지 않아. 매 요청이 독립적이야.

요청 1: [system] + [user: 안녕]
요청 2: [system] + [user: 안녕] + [assistant: 안녕!] + [user: 임베딩이 뭐야?]
요청 3: [system] + [user: 안녕] + ... + [user: write 툴은?]
요청 4: [system] + 위 모든 대화 + [user: 지금 질문]
매번 처음부터 다시 읽는 거야. 그래서 대화가 길어질수록 토큰 소비가 늘어나.

그럼 비효율적이지 않아?
맞아. 그래서 실제로 최적화 기법들이 있어:

기법	설명
Prompt Caching	시스템 프롬프트가 동일하면 캐싱해서 재사용 (Anthropic 지원)
대화 요약	히스토리가 너무 길어지면 앞부분을 요약으로 압축
컨텍스트 윈도우 제한	일정 길이 초과하면 오래된 메시지 잘라냄
OpenClaw도 Anthropic의 prompt caching을 활용해서 시스템 프롬프트 토큰 비용을 줄여.

시각화
채팅 1번째 메시지:
┌─────────────────────────────┐
│ system: SOUL.md+MEMORY.md..│ ← 매번 포함
│ messages: [user: 안녕] │
└─────────────────────────────┘

채팅 5번째 메시지:
┌─────────────────────────────┐
│ system: SOUL.md+MEMORY.md..│ ← 똑같이 포함
│ messages: [ │
│ user: 안녕 │
│ assistant: 안녕! │
│ user: 임베딩이 뭐야? │
│ assistant: 벡터로... │
│ user: 지금 질문 │ ← 누적됨
│ ] │
└─────────────────────────────┘
그래서 긴 대화일수록 점점 무거워지는 거야 🐾

결론은 임베딩은 memory.md 가 많아질때 토큰문제를 해결하는 방법이다.
아직 나에게는 필요없을것같다.


## 주요 변경 사항


## 결과
- 상태:

## 배운내용


## 다음 작업
-

---
