# 업무일지

## 기본 정보
- 날짜: 2026-02-27 (금) 11:00~12:00
- 작성자: hexsera

## 진행 목표
openclaw 트래이싱 환경 구축

## 진행 내용
openclaw 에게 직접 트래이싱 환경 구축해달라고 부탁하였다.

tail -f ~/.openclaw/agents/main/sessions/1100cacd-9a15-40fa-90ad-b3f25fd522b3.jsonl \
  | python3 /home/hexsera/.openclaw/workspace/trace.py -

해당 코드로 트래이싱 가능
단 tool 호출과 같은 어떤 json 이 오는지에 대해 알 수 없다.

## 주요 변경 사항


## 결과
- 상태:

## 배운 내용


## 다음 작업
-

# 업무일지

## 기본 정보
- 날짜: 2026-02-27 (금) 15:30~16:30
- 작성자: hexsera

## 진행 목표
openclaw 툴 호출과정 확인

## 진행 내용
세부 내용 확인을 위해 트래이스 툴 수정
로그 메시지 확인, 그러나 이해하기가 힘들다.

그래서 직접 어떤 MML -> TOOl 은 어떤 데이터가 오는지 알려달라고 질문
anthropic api 가 한 덩어리로 안오고 SEE 로 와서 stop_reason 이라고하는데...
모르겠음


## 주요 변경 사항


## 결과
- 상태:

## 배운 내용


## 다음 작업
-


# 업무일지

## 기본 정보
- 날짜: 2026-02-27 (금) 16:40~17:40
- 작성자: hexsera

## 진행 목표
openclaw memory 를 어떻게 읽는가?

## 진행 내용
memory 분석 보고서 생성.
memory 분석 코드 호출 보고서 생성.

이미 아는 부분이지만 벡터 + 키워드 부분이 좀 궁금하다.
키워드 검색... 이거 미리 만들어진게 아니라 고전적으로 키워드를 찾는 느낌인데? 마치 메모장 ctrl+f 하듯이...

## 주요 변경 사항


## 결과
- 상태:

## 배운 내용


## 다음 작업
-


# 업무일지

## 기본 정보
- 날짜: 2026-02-27 (금) 19:20~20:30
- 작성자: hexsera

## 진행 목표
LLM 과 openclaw 의 데이터 주고받는 형식 조사

## 진행 내용
네이밍 분석.md 생성
Gemini_Tool_사용법.md 생성

이제 LLM 과 TOOL 호출 규격을 알겠다.

```json
{
  "model": "gemini-2.5-flash",
  "system_instruction": {
    "parts": [{ "text": "당신은 유능한 AI 비서입니다." }]
  },
  "contents": [
    {
      "role": "user",
      "parts": [{ "text": "현재 디렉토리 파일 목록을 보여줘" }]
    }
  ],
  "tools": [
    {
      "function_declarations": [
        {
          "name": "exec",
          "description": "셸 명령어를 실행합니다.",
          "parameters": {
            "type": "object",
            "properties": {
              "command": {
                "type": "string",
                "description": "실행할 셸 명령어"
              },
              "workdir": {
                "type": "string",
                "description": "작업 디렉토리 (생략 시 현재 디렉토리)"
              }
            },
            "required": ["command"]
          }
        }
      ]
    }
  ]
}
```

```json
{
  "candidates": [
    {
      "content": {
        "role": "model",
        "parts": [
          {
            "functionCall": {
              "name": "exec",
              "args": {
                "command": "ls -la"
              }
            }
          }
        ]
      },
      "finish_reason": "STOP"
    }
  ]
}
```

항상 api 로 json 규격을 주고 받는다.
보내는 json 에는 시스템프롬프트, 콘텐츠(사용자 말), 툴(이름, 설명, 스키마) 를 한번에 보낸다.

만약 LLM 이 툴을 사용할 생각이 들면 해당 툴을 사용한다는 결정을 내리고 해당 툴 스키마에 맞게 json 을 만들어준다.
그걸 분해해서 쓰고 응답은 미리 코딩된대로 LLM 에게 보낸다.

opencalw 트래이스 
tail -f /tmp/openclaw/api-calls.jsonl | python3 ~/.openclaw/workspace/api-trace.py -

## 주요 변경 사항


## 결과
- 상태:

## 배운 내용


## 다음 작업
-


